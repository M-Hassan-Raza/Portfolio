<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Extended Thinking in LLMs: A Mental Model for Developers | Muhammad Hassan Raza</title><meta name=keywords content="AI,LLM,Extended Thinking,Claude,o1,Developer Tools,Reasoning,Prompt Engineering"><meta name=description content="
Extended thinking isn&rsquo;t just &ldquo;model thinks longer&rdquo;—it&rsquo;s a fundamentally different interaction model. If you&rsquo;re prompting extended thinking models (Claude Opus, o1) the same way you prompt standard models, you&rsquo;re leaving most of the value on the table.
This post is a developer&rsquo;s mental model for working with these systems: when to use them, how to prompt them, and what trade-offs to expect.

How Extended Thinking Actually Works
Standard LLMs generate tokens one at a time, each token conditioned on everything before it. The model &ldquo;thinks&rdquo; only as fast as it speaks. Ask it to solve a complex problem, and it often commits to an approach in the first few tokens, then rationalizes that approach even if it&rsquo;s wrong."><meta name=author content="Muhammad Hassan Raza"><link rel=canonical href=https://mhassan.dev/blog/extended-thinking-llms/><link crossorigin=anonymous href=/assets/css/stylesheet.6fa8809ec4dc8c4d63b9f23b67737295a61f62ab0b6c273fa031fb364c3eb795.css integrity="sha256-b6iAnsTcjE1jufI7Z3NylaYfYqsLbCc/oDH7Nkw+t5U=" rel="preload stylesheet" as=style><link rel=icon href=https://mhassan.dev/assets/favicon.svg><link rel=icon type=image/png sizes=16x16 href=https://mhassan.dev/assets/favicon.svg><link rel=icon type=image/png sizes=32x32 href=https://mhassan.dev/assets/favicon.svg><link rel=apple-touch-icon href=https://mhassan.dev/apple-touch-icon.png><link rel=mask-icon href=https://mhassan.dev/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://mhassan.dev/blog/extended-thinking-llms/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=preload href=/css/extended/extended.css as=style><link rel=stylesheet href=/css/extended/extended.css><link rel=preload href=/fonts/font-family.css as=style><link rel=stylesheet href=/fonts/font-family.css><link rel=preload href=/fonts/Manrope-Regular.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/Manrope-Medium.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/Manrope-Bold.woff2 as=font type=font/woff2 crossorigin><script async src=https://cloud.umami.is/script.js data-website-id=30c7d9d6-abac-4c52-b85a-c0234f863d22></script><script async src="https://www.googletagmanager.com/gtag/js?id=%7b%7d"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","{}")</script><meta property="og:url" content="https://mhassan.dev/blog/extended-thinking-llms/"><meta property="og:site_name" content="Muhammad Hassan Raza"><meta property="og:title" content="Extended Thinking in LLMs: A Mental Model for Developers"><meta property="og:description" content=" Extended thinking isn’t just “model thinks longer”—it’s a fundamentally different interaction model. If you’re prompting extended thinking models (Claude Opus, o1) the same way you prompt standard models, you’re leaving most of the value on the table.
This post is a developer’s mental model for working with these systems: when to use them, how to prompt them, and what trade-offs to expect.
How Extended Thinking Actually Works Standard LLMs generate tokens one at a time, each token conditioned on everything before it. The model “thinks” only as fast as it speaks. Ask it to solve a complex problem, and it often commits to an approach in the first few tokens, then rationalizes that approach even if it’s wrong."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-09-25T10:00:00+05:00"><meta property="article:modified_time" content="2025-09-25T10:00:00+05:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="LLM"><meta property="article:tag" content="Extended Thinking"><meta property="article:tag" content="Claude"><meta property="article:tag" content="O1"><meta property="article:tag" content="Developer Tools"><meta property="og:image" content="https://mhassan.dev/assets/extended-thinking.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://mhassan.dev/assets/extended-thinking.jpg"><meta name=twitter:title content="Extended Thinking in LLMs: A Mental Model for Developers"><meta name=twitter:description content="
Extended thinking isn&rsquo;t just &ldquo;model thinks longer&rdquo;—it&rsquo;s a fundamentally different interaction model. If you&rsquo;re prompting extended thinking models (Claude Opus, o1) the same way you prompt standard models, you&rsquo;re leaving most of the value on the table.
This post is a developer&rsquo;s mental model for working with these systems: when to use them, how to prompt them, and what trade-offs to expect.

How Extended Thinking Actually Works
Standard LLMs generate tokens one at a time, each token conditioned on everything before it. The model &ldquo;thinks&rdquo; only as fast as it speaks. Ask it to solve a complex problem, and it often commits to an approach in the first few tokens, then rationalizes that approach even if it&rsquo;s wrong."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://mhassan.dev/blog/"},{"@type":"ListItem","position":2,"name":"Extended Thinking in LLMs: A Mental Model for Developers","item":"https://mhassan.dev/blog/extended-thinking-llms/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Extended Thinking in LLMs: A Mental Model for Developers","name":"Extended Thinking in LLMs: A Mental Model for Developers","description":" Extended thinking isn\u0026rsquo;t just \u0026ldquo;model thinks longer\u0026rdquo;—it\u0026rsquo;s a fundamentally different interaction model. If you\u0026rsquo;re prompting extended thinking models (Claude Opus, o1) the same way you prompt standard models, you\u0026rsquo;re leaving most of the value on the table.\nThis post is a developer\u0026rsquo;s mental model for working with these systems: when to use them, how to prompt them, and what trade-offs to expect.\nHow Extended Thinking Actually Works Standard LLMs generate tokens one at a time, each token conditioned on everything before it. The model \u0026ldquo;thinks\u0026rdquo; only as fast as it speaks. Ask it to solve a complex problem, and it often commits to an approach in the first few tokens, then rationalizes that approach even if it\u0026rsquo;s wrong.\n","keywords":["AI","LLM","Extended Thinking","Claude","o1","Developer Tools","Reasoning","Prompt Engineering"],"articleBody":" Extended thinking isn’t just “model thinks longer”—it’s a fundamentally different interaction model. If you’re prompting extended thinking models (Claude Opus, o1) the same way you prompt standard models, you’re leaving most of the value on the table.\nThis post is a developer’s mental model for working with these systems: when to use them, how to prompt them, and what trade-offs to expect.\nHow Extended Thinking Actually Works Standard LLMs generate tokens one at a time, each token conditioned on everything before it. The model “thinks” only as fast as it speaks. Ask it to solve a complex problem, and it often commits to an approach in the first few tokens, then rationalizes that approach even if it’s wrong.\nExtended thinking models add an intermediate step: they generate a reasoning trace before producing the final answer. Think of it as the model writing notes in the margin before responding.\nThis matters because:\n1. More tokens = more “working memory.” The reasoning trace gives the model space to consider alternatives, check its work, and revise approaches. It’s like the difference between solving math problems in your head vs. on scratch paper.\n2. The reasoning trace isn’t shown to you. You see the polished output, not the exploratory thinking. This is both a feature (cleaner responses) and a limitation (harder to debug when it goes wrong).\n3. The model can “backtrack” conceptually. Standard models can’t unsay tokens. Extended thinking can reason through an approach, decide it’s wrong, and try another—all before responding.\nClaude Opus vs. o1: Different approaches Both are “thinking models,” but they work differently:\nClaude Opus 4.5:\nExtended thinking via longer internal reasoning Configurable thinking budget Reasoning partially visible via API (for debugging) Optimized for helpfulness and safety alongside reasoning OpenAI o1:\nChain-of-thought at massive scale Hidden reasoning trace (not exposed via API) Optimized for benchmark performance Tends toward longer, more verbose responses In practice, I find Opus better for interactive development work (code review, debugging) and o1 better for competition-style problems (math, algorithms). Your mileage will vary.\nWhen Extended Thinking Helps Not every task benefits from extended thinking. Here’s a rough heuristic:\nGreat for: Complex code generation. Multi-file changes, refactoring, implementing algorithms with edge cases. The model can reason about interactions between components.\nArchitecture decisions. “Here’s our system. What are the tradeoffs of adding a cache here vs. there?” Extended thinking models consider more factors before committing.\nBug diagnosis. Given error messages, logs, and code, the model can reason through possible causes rather than pattern-matching to the most common fix.\nMulti-step reasoning. Any task where the answer depends on intermediate conclusions: tax calculations, game theory, proof verification.\nNot worth it for: Simple lookups. “What’s the syntax for a Python list comprehension?” Fast models give the same answer instantly.\nLatency-sensitive applications. Extended thinking takes 10-60 seconds. If your UX requires sub-second responses, it won’t work.\nHigh-volume, low-complexity tasks. Summarizing 10,000 documents? Use the cheapest, fastest model that works. Extended thinking is expensive overkill.\nTasks requiring current information. Thinking longer doesn’t give the model access to information it doesn’t have. Use retrieval augmentation instead.\nPrompting for Extended Thinking Here’s the counterintuitive part: stop giving step-by-step instructions.\nStandard prompting advice says to break down tasks, provide explicit steps, guide the model through your reasoning. This backfires with extended thinking models.\nWhy detailed instructions hurt When you say “First do X, then do Y, then do Z,” you’re constraining the model’s reasoning. You’ve decided the approach before it can think. If your approach is suboptimal, the model will faithfully execute your suboptimal plan.\nExtended thinking models are better at figuring out approaches than you are (for many tasks). Let them.\nWhat to do instead Provide context, not instructions:\n# Bad \"First, read through the codebase structure. Then, identify files that handle authentication. Next, look for potential security vulnerabilities. Finally, provide recommendations.\" # Good \"Here's our authentication system [files]. We're concerned about security. Analyze this thoroughly and identify any vulnerabilities or improvements.\" The second version lets the model decide how to approach the analysis. It might find approaches you wouldn’t have specified.\nState the goal, not the process:\n# Bad \"Use the following algorithm: first sort by date, then group by category, then calculate averages...\" # Good \"I need to understand spending patterns in this transaction data. What insights can you find?\" Trust the model’s reasoning:\n# Bad \"Think step by step. First consider X. Then consider Y. Show your work.\" # Good \"This is a complex problem. Take your time reasoning through it.\" The “think step by step” prompt was designed for models that didn’t think before answering. Extended thinking models already do this internally. You’re just adding noise.\nReal Prompt Comparison Let me show a concrete example. Task: review a Django view for potential issues.\nStandard model prompt (optimized for GPT-4): Review this Django view for issues. Check for: 1. N+1 queries 2. Missing error handling 3. Security vulnerabilities 4. Performance problems 5. Code style issues For each issue found, explain the problem and provide a fix. [code] This works okay with GPT-4. You’ve told it what to look for.\nExtended thinking prompt (optimized for Opus): Here's a Django view from our production system. This view handles user dashboard data and is called ~5000 times/day. We've had intermittent timeouts but haven't identified the cause. Please thoroughly analyze this code. [code] Notice what changed:\nRemoved the checklist (let the model decide what to look for) Added context (production, call volume, symptom) Broader request (thoroughly analyze vs. check for X) The extended thinking model will likely check everything on the first list plus things you didn’t think to ask about. And it’ll prioritize based on the context (intermittent timeouts → probably an intermittent performance issue, not a style problem).\nCost-Performance Trade-offs Extended thinking is expensive. A complex analysis might use 10-50K tokens of thinking, plus input/output tokens. That’s $0.50-2.00 per query at current Opus pricing.\nWhen to pay for thinking: High-stakes decisions (architecture, security audits) Complex debugging that would take you hours Problems you’ve failed to solve with faster models When to use fast models: Routine code generation Simple Q\u0026A High-volume batch processing Hybrid approach: Use fast models for initial attempts. Escalate to extended thinking when:\nFast model gives wrong answer Fast model’s confidence is low Task is in extended thinking’s sweet spot At Entropy Labs, we route queries based on estimated complexity. Simple queries go to Haiku (fast, cheap). Complex queries with keywords like “debug,” “analyze,” or “architecture” go to Opus.\nPractical Integration Patterns Fallback chains async def analyze_code(code: str, context: str) -\u003e str: # Try fast model first fast_response = await sonnet.analyze(code, context) if fast_response.confidence \u003c 0.7 or \"uncertain\" in fast_response: # Escalate to extended thinking return await opus.analyze(code, context, extended_thinking=True) return fast_response Streaming extended thinking Extended thinking can take 30-60 seconds. Don’t leave users staring at a spinner:\nasync def stream_analysis(query: str): # Send status updates while thinking yield {\"status\": \"analyzing\", \"stage\": \"reading code\"} async for event in opus.stream(query): if event.type == \"thinking\": yield {\"status\": \"analyzing\", \"stage\": \"reasoning\"} elif event.type == \"response\": yield {\"status\": \"complete\", \"result\": event.content} Managing user expectations Extended thinking responses are worth waiting for—but users don’t know that. Set expectations:\n\"This is a complex analysis. I'll take 30-60 seconds to think through this carefully. For quick questions, ask me directly instead.\" The Bottom Line Extended thinking is the biggest practical advance in LLMs since GPT-4. But it requires a mindset shift:\nStop micromanaging. Provide context, not instructions. Use it selectively. Extended thinking for complex problems, fast models for everything else. Budget for latency. 30-60 seconds is the new normal for hard problems. Trust but verify. Extended thinking is more reliable, not infallible. The models that think before they speak are finally here. Learn to let them think.\n","wordCount":"1288","inLanguage":"en","image":"https://mhassan.dev/assets/extended-thinking.jpg","datePublished":"2025-09-25T10:00:00+05:00","dateModified":"2025-09-25T10:00:00+05:00","author":{"@type":"Person","name":"Muhammad Hassan Raza"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://mhassan.dev/blog/extended-thinking-llms/"},"publisher":{"@type":"Organization","name":"Muhammad Hassan Raza","logo":{"@type":"ImageObject","url":"https://mhassan.dev/assets/favicon.svg"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://mhassan.dev/ accesskey=h title="Muhammad Hassan Raza (Alt + H)">Muhammad Hassan Raza</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://mhassan.dev/book-a-call/ title="Book a Call"><span><svg class="menu-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1" stroke-linecap="round" stroke-linejoin="round"><path d="M8.26 1.289l-1.564.772c-5.793 3.02 2.798 20.944 9.31 20.944.46.0.904-.094 1.317-.284l1.542-.755-2.898-5.594-1.54.754c-.181.087-.384.134-.597.134-2.561.0-6.841-8.204-4.241-9.596l1.546-.763L8.26 1.289zM16.006 24C10.326 24 3.785 12.886 3.785 6.168c0-2.419.833-4.146 2.457-4.992l2.382-1.176 3.857 7.347-2.437 1.201c-1.439.772 2.409 8.424 3.956 7.68l2.399-1.179 3.816 7.36s-2.36 1.162-2.476 1.215c-.547.251-1.129.376-1.733.376"/></svg>Book a Call</span></a></li><li><a href=https://mhassan.dev/projects/ title=Projects><span><svg class="menu-icon" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1" stroke-linecap="round" stroke-linejoin="round"><path d="M11 5h13v17H0V2h8l3 3zM1 3v18h22V6H10.586l-3-3H1z"/></svg>Projects</span></a></li><li><a href=https://mhassan.dev/about/ title=About><span><svg class="menu-icon" shape-rendering="geometricPrecision" viewBox="-1 0 24 24" fill="none" stroke="currentColor" stroke-width="1" stroke-linecap="round" stroke-linejoin="round"><path d="M12 0c6.623.0 12 5.377 12 12s-5.377 12-12 12S0 18.623.0 12 5.377.0 12 0zm8.127 19.41c-.282-.401-.772-.654-1.624-.85-3.848-.906-4.097-1.501-4.352-2.059-.259-.565-.19-1.23.205-1.977 1.726-3.257 2.09-6.024 1.027-7.79C14.709 5.615 13.508 5 12 5c-1.521.0-2.732.626-3.409 1.763-1.066 1.789-.693 4.544 1.049 7.757.402.742.476 1.406.22 1.974-.265.586-.611 1.19-4.365 2.066-.852.196-1.342.449-1.623.848C5.884 21.615 8.782 23 12 23s6.115-1.385 8.127-3.59zm.65-.782C22.172 16.784 23 14.488 23 12c0-6.071-4.929-11-11-11S1 5.929 1 12c0 2.487.827 4.783 2.222 6.626.409-.452 1.049-.81 2.049-1.041 2.025-.462 3.376-.836 3.678-1.502.122-.272.061-.628-.188-1.087-1.917-3.535-2.282-6.641-1.03-8.745C8.584 4.82 10.139 4 12 4c1.845.0 3.391.808 4.24 2.218 1.251 2.079.896 5.195-1 8.774-.245.463-.304.821-.179 1.094.305.668 1.644 1.038 3.667 1.499 1 .23 1.64.59 2.049 1.043z"/></svg>About</span></a></li><li><a href=https://mhassan.dev/search/ title="Search (Alt + /)" accesskey=/><span><svg class="menu-icon" shape-rendering="geometricPrecision" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="1" stroke-linecap="round" stroke-linejoin="round"><path d="M15.853 16.56C14.17 18.077 11.942 19 9.5 19 4.257 19 0 14.743.0 9.5S4.257.0 9.5.0 19 4.257 19 9.5c0 2.442-.923 4.67-2.44 6.353l7.44 7.44-.707.707-7.44-7.44zm-6.353-15.56c4.691.0 8.5 3.809 8.5 8.5S14.191 18 9.5 18 1 14.191 1 9.5 4.809 1 9.5 1z"/></svg>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://mhassan.dev/>Home</a>&nbsp;»&nbsp;<a href=https://mhassan.dev/blog/>Blog</a></div><h1 class=post-title>Extended Thinking in LLMs: A Mental Model for Developers</h1><div class=post-meta><span title='2025-09-25 10:00:00 +0500 +0500'>September 25, 2025</span>&nbsp;·&nbsp;<span>7 min</span>&nbsp;·&nbsp;<span>Muhammad Hassan Raza</span></div></header><figure class=entry-cover><img loading=lazy src=https://mhassan.dev/assets/extended-thinking.jpg alt="Extended Thinking LLMs"></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#how-extended-thinking-actually-works aria-label="How Extended Thinking Actually Works">How Extended Thinking Actually Works</a><ul><li><a href=#claude-opus-vs-o1-different-approaches aria-label="Claude Opus vs. o1: Different approaches">Claude Opus vs. o1: Different approaches</a></li></ul></li><li><a href=#when-extended-thinking-helps aria-label="When Extended Thinking Helps">When Extended Thinking Helps</a><ul><li><a href=#great-for aria-label="Great for:">Great for:</a></li><li><a href=#not-worth-it-for aria-label="Not worth it for:">Not worth it for:</a></li></ul></li><li><a href=#prompting-for-extended-thinking aria-label="Prompting for Extended Thinking">Prompting for Extended Thinking</a><ul><li><a href=#why-detailed-instructions-hurt aria-label="Why detailed instructions hurt">Why detailed instructions hurt</a></li><li><a href=#what-to-do-instead aria-label="What to do instead">What to do instead</a></li></ul></li><li><a href=#real-prompt-comparison aria-label="Real Prompt Comparison">Real Prompt Comparison</a><ul><li><a href=#standard-model-prompt-optimized-for-gpt-4 aria-label="Standard model prompt (optimized for GPT-4):">Standard model prompt (optimized for GPT-4):</a></li><li><a href=#extended-thinking-prompt-optimized-for-opus aria-label="Extended thinking prompt (optimized for Opus):">Extended thinking prompt (optimized for Opus):</a></li></ul></li><li><a href=#cost-performance-trade-offs aria-label="Cost-Performance Trade-offs">Cost-Performance Trade-offs</a><ul><li><a href=#when-to-pay-for-thinking aria-label="When to pay for thinking:">When to pay for thinking:</a></li><li><a href=#when-to-use-fast-models aria-label="When to use fast models:">When to use fast models:</a></li><li><a href=#hybrid-approach aria-label="Hybrid approach:">Hybrid approach:</a></li></ul></li><li><a href=#practical-integration-patterns aria-label="Practical Integration Patterns">Practical Integration Patterns</a><ul><li><a href=#fallback-chains aria-label="Fallback chains">Fallback chains</a></li><li><a href=#streaming-extended-thinking aria-label="Streaming extended thinking">Streaming extended thinking</a></li><li><a href=#managing-user-expectations aria-label="Managing user expectations">Managing user expectations</a></li></ul></li><li><a href=#the-bottom-line aria-label="The Bottom Line">The Bottom Line</a></li></ul></div></details></div><div class=post-content><div style=text-align:justify><p>Extended thinking isn&rsquo;t just &ldquo;model thinks longer&rdquo;—it&rsquo;s a fundamentally different interaction model. If you&rsquo;re prompting extended thinking models (Claude Opus, o1) the same way you prompt standard models, you&rsquo;re leaving most of the value on the table.</p><p>This post is a developer&rsquo;s mental model for working with these systems: when to use them, how to prompt them, and what trade-offs to expect.</p><hr><h2 id=how-extended-thinking-actually-works><span style=color:#8ac7db>How Extended Thinking Actually Works</span><a hidden class=anchor aria-hidden=true href=#how-extended-thinking-actually-works>#</a></h2><p>Standard LLMs generate tokens one at a time, each token conditioned on everything before it. The model &ldquo;thinks&rdquo; only as fast as it speaks. Ask it to solve a complex problem, and it often commits to an approach in the first few tokens, then rationalizes that approach even if it&rsquo;s wrong.</p><p>Extended thinking models add an intermediate step: they generate a reasoning trace before producing the final answer. Think of it as the model writing notes in the margin before responding.</p><p>This matters because:</p><p><strong>1. More tokens = more &ldquo;working memory.&rdquo;</strong> The reasoning trace gives the model space to consider alternatives, check its work, and revise approaches. It&rsquo;s like the difference between solving math problems in your head vs. on scratch paper.</p><p><strong>2. The reasoning trace isn&rsquo;t shown to you.</strong> You see the polished output, not the exploratory thinking. This is both a feature (cleaner responses) and a limitation (harder to debug when it goes wrong).</p><p><strong>3. The model can &ldquo;backtrack&rdquo; conceptually.</strong> Standard models can&rsquo;t unsay tokens. Extended thinking can reason through an approach, decide it&rsquo;s wrong, and try another—all before responding.</p><h3 id=claude-opus-vs-o1-different-approaches>Claude Opus vs. o1: Different approaches<a hidden class=anchor aria-hidden=true href=#claude-opus-vs-o1-different-approaches>#</a></h3><p>Both are &ldquo;thinking models,&rdquo; but they work differently:</p><p><strong>Claude Opus 4.5:</strong></p><ul><li>Extended thinking via longer internal reasoning</li><li>Configurable thinking budget</li><li>Reasoning partially visible via API (for debugging)</li><li>Optimized for helpfulness and safety alongside reasoning</li></ul><p><strong>OpenAI o1:</strong></p><ul><li>Chain-of-thought at massive scale</li><li>Hidden reasoning trace (not exposed via API)</li><li>Optimized for benchmark performance</li><li>Tends toward longer, more verbose responses</li></ul><p>In practice, I find Opus better for interactive development work (code review, debugging) and o1 better for competition-style problems (math, algorithms). Your mileage will vary.</p><hr><h2 id=when-extended-thinking-helps><span style=color:#ffb4a2>When Extended Thinking Helps</span><a hidden class=anchor aria-hidden=true href=#when-extended-thinking-helps>#</a></h2><p>Not every task benefits from extended thinking. Here&rsquo;s a rough heuristic:</p><h3 id=great-for>Great for:<a hidden class=anchor aria-hidden=true href=#great-for>#</a></h3><p><strong>Complex code generation.</strong> Multi-file changes, refactoring, implementing algorithms with edge cases. The model can reason about interactions between components.</p><p><strong>Architecture decisions.</strong> &ldquo;Here&rsquo;s our system. What are the tradeoffs of adding a cache here vs. there?&rdquo; Extended thinking models consider more factors before committing.</p><p><strong>Bug diagnosis.</strong> Given error messages, logs, and code, the model can reason through possible causes rather than pattern-matching to the most common fix.</p><p><strong>Multi-step reasoning.</strong> Any task where the answer depends on intermediate conclusions: tax calculations, game theory, proof verification.</p><h3 id=not-worth-it-for>Not worth it for:<a hidden class=anchor aria-hidden=true href=#not-worth-it-for>#</a></h3><p><strong>Simple lookups.</strong> &ldquo;What&rsquo;s the syntax for a Python list comprehension?&rdquo; Fast models give the same answer instantly.</p><p><strong>Latency-sensitive applications.</strong> Extended thinking takes 10-60 seconds. If your UX requires sub-second responses, it won&rsquo;t work.</p><p><strong>High-volume, low-complexity tasks.</strong> Summarizing 10,000 documents? Use the cheapest, fastest model that works. Extended thinking is expensive overkill.</p><p><strong>Tasks requiring current information.</strong> Thinking longer doesn&rsquo;t give the model access to information it doesn&rsquo;t have. Use retrieval augmentation instead.</p><hr><h2 id=prompting-for-extended-thinking><span style=color:#8ac7db>Prompting for Extended Thinking</span><a hidden class=anchor aria-hidden=true href=#prompting-for-extended-thinking>#</a></h2><p>Here&rsquo;s the counterintuitive part: <strong>stop giving step-by-step instructions.</strong></p><p>Standard prompting advice says to break down tasks, provide explicit steps, guide the model through your reasoning. This backfires with extended thinking models.</p><h3 id=why-detailed-instructions-hurt>Why detailed instructions hurt<a hidden class=anchor aria-hidden=true href=#why-detailed-instructions-hurt>#</a></h3><p>When you say &ldquo;First do X, then do Y, then do Z,&rdquo; you&rsquo;re constraining the model&rsquo;s reasoning. You&rsquo;ve decided the approach before it can think. If your approach is suboptimal, the model will faithfully execute your suboptimal plan.</p><p>Extended thinking models are <em>better at figuring out approaches than you are</em> (for many tasks). Let them.</p><h3 id=what-to-do-instead>What to do instead<a hidden class=anchor aria-hidden=true href=#what-to-do-instead>#</a></h3><p><strong>Provide context, not instructions:</strong></p><pre tabindex=0><code># Bad
&#34;First, read through the codebase structure. Then, identify files
that handle authentication. Next, look for potential security
vulnerabilities. Finally, provide recommendations.&#34;

# Good
&#34;Here&#39;s our authentication system [files]. We&#39;re concerned about
security. Analyze this thoroughly and identify any vulnerabilities
or improvements.&#34;
</code></pre><p>The second version lets the model decide how to approach the analysis. It might find approaches you wouldn&rsquo;t have specified.</p><p><strong>State the goal, not the process:</strong></p><pre tabindex=0><code># Bad
&#34;Use the following algorithm: first sort by date, then group by
category, then calculate averages...&#34;

# Good
&#34;I need to understand spending patterns in this transaction data.
What insights can you find?&#34;
</code></pre><p><strong>Trust the model&rsquo;s reasoning:</strong></p><pre tabindex=0><code># Bad
&#34;Think step by step. First consider X. Then consider Y.
Show your work.&#34;

# Good
&#34;This is a complex problem. Take your time reasoning through it.&#34;
</code></pre><p>The &ldquo;think step by step&rdquo; prompt was designed for models that didn&rsquo;t think before answering. Extended thinking models already do this internally. You&rsquo;re just adding noise.</p><hr><h2 id=real-prompt-comparison><span style=color:#ffb4a2>Real Prompt Comparison</span><a hidden class=anchor aria-hidden=true href=#real-prompt-comparison>#</a></h2><p>Let me show a concrete example. Task: review a Django view for potential issues.</p><h3 id=standard-model-prompt-optimized-for-gpt-4>Standard model prompt (optimized for GPT-4):<a hidden class=anchor aria-hidden=true href=#standard-model-prompt-optimized-for-gpt-4>#</a></h3><pre tabindex=0><code>Review this Django view for issues. Check for:
1. N+1 queries
2. Missing error handling
3. Security vulnerabilities
4. Performance problems
5. Code style issues

For each issue found, explain the problem and provide a fix.

[code]
</code></pre><p>This works okay with GPT-4. You&rsquo;ve told it what to look for.</p><h3 id=extended-thinking-prompt-optimized-for-opus>Extended thinking prompt (optimized for Opus):<a hidden class=anchor aria-hidden=true href=#extended-thinking-prompt-optimized-for-opus>#</a></h3><pre tabindex=0><code>Here&#39;s a Django view from our production system. This view handles
user dashboard data and is called ~5000 times/day. We&#39;ve had
intermittent timeouts but haven&#39;t identified the cause.

Please thoroughly analyze this code.

[code]
</code></pre><p>Notice what changed:</p><ul><li>Removed the checklist (let the model decide what to look for)</li><li>Added context (production, call volume, symptom)</li><li>Broader request (thoroughly analyze vs. check for X)</li></ul><p>The extended thinking model will likely check everything on the first list <em>plus</em> things you didn&rsquo;t think to ask about. And it&rsquo;ll prioritize based on the context (intermittent timeouts → probably an intermittent performance issue, not a style problem).</p><hr><h2 id=cost-performance-trade-offs><span style=color:#8ac7db>Cost-Performance Trade-offs</span><a hidden class=anchor aria-hidden=true href=#cost-performance-trade-offs>#</a></h2><p>Extended thinking is expensive. A complex analysis might use 10-50K tokens of thinking, plus input/output tokens. That&rsquo;s $0.50-2.00 per query at current Opus pricing.</p><h3 id=when-to-pay-for-thinking>When to pay for thinking:<a hidden class=anchor aria-hidden=true href=#when-to-pay-for-thinking>#</a></h3><ul><li>High-stakes decisions (architecture, security audits)</li><li>Complex debugging that would take you hours</li><li>Problems you&rsquo;ve failed to solve with faster models</li></ul><h3 id=when-to-use-fast-models>When to use fast models:<a hidden class=anchor aria-hidden=true href=#when-to-use-fast-models>#</a></h3><ul><li>Routine code generation</li><li>Simple Q&amp;A</li><li>High-volume batch processing</li></ul><h3 id=hybrid-approach>Hybrid approach:<a hidden class=anchor aria-hidden=true href=#hybrid-approach>#</a></h3><p>Use fast models for initial attempts. Escalate to extended thinking when:</p><ul><li>Fast model gives wrong answer</li><li>Fast model&rsquo;s confidence is low</li><li>Task is in extended thinking&rsquo;s sweet spot</li></ul><p>At Entropy Labs, we route queries based on estimated complexity. Simple queries go to Haiku (fast, cheap). Complex queries with keywords like &ldquo;debug,&rdquo; &ldquo;analyze,&rdquo; or &ldquo;architecture&rdquo; go to Opus.</p><hr><h2 id=practical-integration-patterns><span style=color:#ffb4a2>Practical Integration Patterns</span><a hidden class=anchor aria-hidden=true href=#practical-integration-patterns>#</a></h2><h3 id=fallback-chains>Fallback chains<a hidden class=anchor aria-hidden=true href=#fallback-chains>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>analyze_code</span>(code: str, context: str) <span style=color:#f92672>-&gt;</span> str:
</span></span><span style=display:flex><span>    <span style=color:#75715e># Try fast model first</span>
</span></span><span style=display:flex><span>    fast_response <span style=color:#f92672>=</span> <span style=color:#66d9ef>await</span> sonnet<span style=color:#f92672>.</span>analyze(code, context)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> fast_response<span style=color:#f92672>.</span>confidence <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>0.7</span> <span style=color:#f92672>or</span> <span style=color:#e6db74>&#34;uncertain&#34;</span> <span style=color:#f92672>in</span> fast_response:
</span></span><span style=display:flex><span>        <span style=color:#75715e># Escalate to extended thinking</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#66d9ef>await</span> opus<span style=color:#f92672>.</span>analyze(code, context, extended_thinking<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> fast_response
</span></span></code></pre></div><h3 id=streaming-extended-thinking>Streaming extended thinking<a hidden class=anchor aria-hidden=true href=#streaming-extended-thinking>#</a></h3><p>Extended thinking can take 30-60 seconds. Don&rsquo;t leave users staring at a spinner:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>async</span> <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>stream_analysis</span>(query: str):
</span></span><span style=display:flex><span>    <span style=color:#75715e># Send status updates while thinking</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>yield</span> {<span style=color:#e6db74>&#34;status&#34;</span>: <span style=color:#e6db74>&#34;analyzing&#34;</span>, <span style=color:#e6db74>&#34;stage&#34;</span>: <span style=color:#e6db74>&#34;reading code&#34;</span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>async</span> <span style=color:#66d9ef>for</span> event <span style=color:#f92672>in</span> opus<span style=color:#f92672>.</span>stream(query):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> event<span style=color:#f92672>.</span>type <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;thinking&#34;</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>yield</span> {<span style=color:#e6db74>&#34;status&#34;</span>: <span style=color:#e6db74>&#34;analyzing&#34;</span>, <span style=color:#e6db74>&#34;stage&#34;</span>: <span style=color:#e6db74>&#34;reasoning&#34;</span>}
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>elif</span> event<span style=color:#f92672>.</span>type <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;response&#34;</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>yield</span> {<span style=color:#e6db74>&#34;status&#34;</span>: <span style=color:#e6db74>&#34;complete&#34;</span>, <span style=color:#e6db74>&#34;result&#34;</span>: event<span style=color:#f92672>.</span>content}
</span></span></code></pre></div><h3 id=managing-user-expectations>Managing user expectations<a hidden class=anchor aria-hidden=true href=#managing-user-expectations>#</a></h3><p>Extended thinking responses are worth waiting for—but users don&rsquo;t know that. Set expectations:</p><pre tabindex=0><code>&#34;This is a complex analysis. I&#39;ll take 30-60 seconds to
think through this carefully. For quick questions, ask
me directly instead.&#34;
</code></pre><hr><h2 id=the-bottom-line><span style=color:#8ac7db>The Bottom Line</span><a hidden class=anchor aria-hidden=true href=#the-bottom-line>#</a></h2><p>Extended thinking is the biggest practical advance in LLMs since GPT-4. But it requires a mindset shift:</p><ol><li><strong>Stop micromanaging.</strong> Provide context, not instructions.</li><li><strong>Use it selectively.</strong> Extended thinking for complex problems, fast models for everything else.</li><li><strong>Budget for latency.</strong> 30-60 seconds is the new normal for hard problems.</li><li><strong>Trust but verify.</strong> Extended thinking is more reliable, not infallible.</li></ol><p>The models that think before they speak are finally here. Learn to let them think.</p></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://mhassan.dev/tags/ai>AI</a></li><li><a href=https://mhassan.dev/tags/llm>LLM</a></li><li><a href=https://mhassan.dev/tags/extended-thinking>Extended Thinking</a></li><li><a href=https://mhassan.dev/tags/claude>Claude</a></li><li><a href=https://mhassan.dev/tags/o1>o1</a></li><li><a href=https://mhassan.dev/tags/developer-tools>Developer Tools</a></li><li><a href=https://mhassan.dev/tags/reasoning>Reasoning</a></li><li><a href=https://mhassan.dev/tags/prompt-engineering>Prompt Engineering</a></li></ul><nav class=paginav><a class=prev href=https://mhassan.dev/blog/model-context-protocol/><span class=title>« Prev</span><br><span>Model Context Protocol: Why This Matters More Than You Think</span>
</a><a class=next href=https://mhassan.dev/blog/ai-features-users-want/><span class=title>Next »</span><br><span>AI Features Your Users Actually Want (Hint: Not Another Chatbot)</span></a></nav></footer><div class=giscus-container><script src=https://giscus.app/client.js data-repo=M-Hassan-Raza/Portfolio data-repo-id=R_kgDON3Oajw data-category=General data-category-id=DIC_kwDON3Oaj84Cm3y9 data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async></script></div><script>function getTheme(){return document.body.classList.contains("dark")?"dark":"light"}function updateGiscusTheme(){const e=document.querySelector("iframe.giscus-frame");if(!e){setTimeout(updateGiscusTheme,300);return}const t=getTheme();e.contentWindow.postMessage({giscus:{setConfig:{theme:t}}},"https://giscus.app")}localStorage.getItem("pref-theme")==="dark"&&updateGiscusTheme();const observer=new MutationObserver(()=>{updateGiscusTheme()});observer.observe(document.body,{attributes:!0,attributeFilter:["class"]})</script></article></main><footer class=footer><span>&copy; 2026 <a href=https://mhassan.dev/>Muhammad Hassan Raza</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>(function(){try{if(window.__hasLoggedConsoleBrand)return;var n=getComputedStyle(document.documentElement),e=(n.getPropertyValue("--primary")||"").trim(),t=(n.getPropertyValue("--secondary")||"").trim(),s=e?"hsl("+e+")":"#4f46e5",o=t?"hsl("+t+")":"#facc15",i="color: "+s+"; font-weight: bold; font-family: monospace; font-size: 12px; line-height: 1.2;",a="color: "+o+"; font-weight: bold; font-family: monospace; font-size: 10px;",r=`%c
███████╗ ██████╗ ██████╗     ████████╗██╗  ██╗███████╗
██╔════╝██╔═══██╗██╔══██╗    ╚══██╔══╝██║  ██║██╔════╝
█████╗  ██║   ██║██████╔╝       ██║   ███████║█████╗  
██╔══╝  ██║   ██║██╔══██╗       ██║   ██╔══██║██╔══╝  
██║     ╚██████╔╝██║  ██║       ██║   ██║  ██║███████╗
╚═╝      ╚═════╝ ╚═╝  ╚═╝       ╚═╝   ╚═╝  ╚═╝╚══════╝
                                                        
███████╗███╗   ███╗██████╗ ███████╗██████╗  ██████╗ ██████╗ 
██╔════╝████╗ ████║██╔══██╗██╔════╝██╔══██╗██╔═══██╗██╔══██╗
█████╗  ██╔████╔██║██████╔╝█████╗  ██████╔╝██║   ██║██████╔╝
██╔══╝  ██║╚██╔╝██║██╔═══╝ ██╔══╝  ██╔══██╗██║   ██║██╔══██╗
███████╗██║ ╚═╝ ██║██║     ███████╗██║  ██║╚██████╔╝██║  ██║
╚══════╝╚═╝     ╚═╝╚═╝     ╚══════╝╚═╝  ╚═╝ ╚═════╝ ╚═╝  ╚═╝
%c
⚔️ In the grim darkness of the dev console, there is only code...`;console.log(r,i,a),window.__hasLoggedConsoleBrand=!0}catch{console.log("⚔️ In the grim darkness of the dev console, there is only code..."),window.__hasLoggedConsoleBrand=!0}})()</script><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>